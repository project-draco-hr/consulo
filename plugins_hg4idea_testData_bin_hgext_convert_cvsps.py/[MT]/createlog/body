def createlog(ui, directory=None, root='', rlog=True, cache=None):
    'Collect the CVS rlog'
    _scache = {}

    def scache(s):
        'return a shared version of a string'
        return _scache.setdefault(s, s)
    ui.status(_('collecting CVS rlog\n'))
    log = []
    re_00 = re.compile('RCS file: (.+)$')
    re_01 = re.compile('cvs \\[r?log aborted\\]: (.+)$')
    re_02 = re.compile('cvs (r?log|server): (.+)\n$')
    re_03 = re.compile("(Cannot access.+CVSROOT)|(can't create temporary directory.+)$")
    re_10 = re.compile('Working file: (.+)$')
    re_20 = re.compile('symbolic names:')
    re_30 = re.compile('\t(.+): ([\\d.]+)$')
    re_31 = re.compile('----------------------------$')
    re_32 = re.compile('=============================================================================$')
    re_50 = re.compile('revision ([\\d.]+)(\\s+locked by:\\s+.+;)?$')
    re_60 = re.compile('date:\\s+(.+);\\s+author:\\s+(.+);\\s+state:\\s+(.+?);(\\s+lines:\\s+(\\+\\d+)?\\s+(-\\d+)?;)?(.*mergepoint:\\s+([^;]+);)?')
    re_70 = re.compile('branches: (.+);$')
    file_added_re = re.compile('file [^/]+ was (initially )?added on branch')
    prefix = ''
    if (directory is None):
        try:
            prefix = open(os.path.join('CVS', 'Repository')).read().strip()
            directory = prefix
            if (prefix == '.'):
                prefix = ''
        except IOError:
            raise logerror(_('not a CVS sandbox'))
        if (prefix and (not prefix.endswith(os.sep))):
            prefix += os.sep
        try:
            root = open(os.path.join('CVS', 'Root')).read().strip()
        except IOError:
            pass
    if (not root):
        root = os.environ.get('CVSROOT', '')
    oldlog = []
    date = None
    if cache:
        cachedir = os.path.expanduser('~/.hg.cvsps')
        if (not os.path.exists(cachedir)):
            os.mkdir(cachedir)
        cachefile = (root.split(':') + [directory, 'cache'])
        cachefile = ['-'.join(re.findall('\\w+', s)) for s in cachefile if s]
        cachefile = os.path.join(cachedir, '.'.join([s for s in cachefile if s]))
    if (cache == 'update'):
        try:
            ui.note((_('reading cvs log cache %s\n') % cachefile))
            oldlog = pickle.load(open(cachefile))
            ui.note((_('cache has %d log entries\n') % len(oldlog)))
        except Exception as e:
            ui.note((_('error reading cache: %r\n') % e))
        if oldlog:
            date = oldlog[(-1)].date
            date = util.datestr(date, '%Y/%m/%d %H:%M:%S %1%2')
    cmd = ['cvs', '-q']
    if root:
        cmd.append(('-d%s' % root))
        p = util.normpath(getrepopath(root))
        if (not p.endswith('/')):
            p += '/'
        if prefix:
            prefix = (p + util.normpath(prefix))
        else:
            prefix = p
    cmd.append(['log', 'rlog'][rlog])
    if date:
        cmd.append(('-d>%s' % date))
    cmd.append(directory)
    tags = {}
    branchmap = {}
    state = 0
    store = False
    cmd = [util.shellquote(arg) for arg in cmd]
    ui.note((_('running %s\n') % ' '.join(cmd)))
    ui.debug(('prefix=%r directory=%r root=%r\n' % (prefix, directory, root)))
    pfp = util.popen(' '.join(cmd))
    peek = pfp.readline()
    while True:
        line = peek
        if (line == ''):
            break
        peek = pfp.readline()
        if line.endswith('\n'):
            line = line[:(-1)]
        if (state == 0):
            match = re_00.match(line)
            if match:
                rcs = match.group(1)
                tags = {}
                if rlog:
                    filename = util.normpath(rcs[:(-2)])
                    if filename.startswith(prefix):
                        filename = filename[len(prefix):]
                    if filename.startswith('/'):
                        filename = filename[1:]
                    if filename.startswith('Attic/'):
                        filename = filename[6:]
                    else:
                        filename = filename.replace('/Attic/', '/')
                    state = 2
                    continue
                state = 1
                continue
            match = re_01.match(line)
            if match:
                raise Exception(match.group(1))
            match = re_02.match(line)
            if match:
                raise Exception(match.group(2))
            if re_03.match(line):
                raise Exception(line)
        elif (state == 1):
            match = re_10.match(line)
            assert match, _('RCS file must be followed by working file')
            filename = util.normpath(match.group(1))
            state = 2
        elif (state == 2):
            if re_20.match(line):
                branchmap = {}
                state = 3
        elif (state == 3):
            match = re_30.match(line)
            if match:
                rev = [int(x) for x in match.group(2).split('.')]
                revn = len(rev)
                if ((revn > 3) and ((revn % 2) == 0) and (rev[(-2)] == 0)):
                    rev = (rev[:(-2)] + rev[(-1):])
                rev = tuple(rev)
                if (rev not in tags):
                    tags[rev] = []
                tags[rev].append(match.group(1))
                branchmap[match.group(1)] = match.group(2)
            elif re_31.match(line):
                state = 5
            elif re_32.match(line):
                state = 0
        elif (state == 4):
            if re_31.match(line):
                state = 5
            else:
                assert (not re_32.match(line)), _('must have at least some revisions')
        elif (state == 5):
            match = re_50.match(line)
            assert match, _('expected revision number')
            e = logentry(rcs=scache(rcs), file=scache(filename), revision=tuple([int(x) for x in match.group(1).split('.')]), branches=[], parent=None)
            state = 6
        elif (state == 6):
            match = re_60.match(line)
            assert match, _('revision must be followed by date line')
            d = match.group(1)
            if (d[2] == '/'):
                d = ('19' + d)
            if (len(d.split()) != 3):
                d = (d + ' UTC')
            e.date = util.parsedate(d, ['%y/%m/%d %H:%M:%S', '%Y/%m/%d %H:%M:%S', '%Y-%m-%d %H:%M:%S'])
            e.author = scache(match.group(2))
            e.dead = (match.group(3).lower() == 'dead')
            if match.group(5):
                if match.group(6):
                    e.lines = (int(match.group(5)), int(match.group(6)))
                else:
                    e.lines = (int(match.group(5)), 0)
            elif match.group(6):
                e.lines = (0, int(match.group(6)))
            else:
                e.lines = None
            if match.group(7):
                myrev = match.group(8).split('.')
                if (len(myrev) == 2):
                    e.mergepoint = 'HEAD'
                else:
                    myrev = '.'.join((myrev[:(-2)] + ['0', myrev[(-2)]]))
                    branches = [b for b in branchmap if (branchmap[b] == myrev)]
                    assert (len(branches) == 1), ('unknown branch: %s' % e.mergepoint)
                    e.mergepoint = branches[0]
            else:
                e.mergepoint = None
            e.comment = []
            state = 7
        elif (state == 7):
            m = re_70.match(line)
            if m:
                e.branches = [tuple([int(y) for y in x.strip().split('.')]) for x in m.group(1).split(';')]
                state = 8
            elif (re_31.match(line) and re_50.match(peek)):
                state = 5
                store = True
            elif re_32.match(line):
                state = 0
                store = True
            else:
                e.comment.append(line)
        elif (state == 8):
            if re_31.match(line):
                state = 5
                store = True
            elif re_32.match(line):
                state = 0
                store = True
            else:
                e.comment.append(line)
        if (store and e.dead and (e.revision[(-1)] == 1) and (len(e.comment) == 1) and file_added_re.match(e.comment[0])):
            ui.debug(('found synthetic revision in %s: %r\n' % (e.rcs, e.comment[0])))
            e.synthetic = True
        if store:
            store = False
            e.tags = sorted([scache(x) for x in tags.get(e.revision, [])])
            e.comment = scache('\n'.join(e.comment))
            revn = len(e.revision)
            if ((revn > 3) and ((revn % 2) == 0)):
                e.branch = tags.get(e.revision[:(-1)], [None])[0]
            else:
                e.branch = None
            branchpoints = set()
            for (branch, revision) in branchmap.iteritems():
                revparts = tuple([int(i) for i in revision.split('.')])
                if (len(revparts) < 2):
                    continue
                if ((revparts[(-2)] == 0) and ((revparts[(-1)] % 2) == 0)):
                    if (revparts[:(-2)] == e.revision):
                        branchpoints.add(branch)
                elif (revparts == (1, 1, 1)):
                    if (revparts in e.branches):
                        branchpoints.add(branch)
            e.branchpoints = branchpoints
            log.append(e)
            if ((len(log) % 100) == 0):
                ui.status((util.ellipsis(('%d %s' % (len(log), e.file)), 80) + '\n'))
    log.sort(key=(lambda x: (x.rcs, x.revision)))
    versions = {}
    for e in log:
        branch = e.revision[:(-1)]
        p = versions.get((e.rcs, branch), None)
        if (p is None):
            p = e.revision[:(-2)]
        e.parent = p
        versions[(e.rcs, branch)] = e.revision
    if cache:
        if log:
            log.sort(key=(lambda x: x.date))
            if (oldlog and (oldlog[(-1)].date >= log[0].date)):
                raise logerror(_('log cache overlaps with new log entries, re-run without cache.'))
            log = (oldlog + log)
            ui.note((_('writing cvs log cache %s\n') % cachefile))
            pickle.dump(log, open(cachefile, 'w'))
        else:
            log = oldlog
    ui.status((_('%d log entries\n') % len(log)))
    hook.hook(ui, None, 'cvslog', True, log=log)
    return log
