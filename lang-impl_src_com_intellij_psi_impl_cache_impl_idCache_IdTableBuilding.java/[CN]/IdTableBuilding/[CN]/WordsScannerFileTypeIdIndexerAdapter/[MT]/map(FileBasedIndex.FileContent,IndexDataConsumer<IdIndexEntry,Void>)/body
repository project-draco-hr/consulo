{
  final CharSequence chars=inputData.content;
  final char[] charsArray=CharArrayUtil.fromSequenceWithoutCopying(chars);
  myScanner.processWords(chars,new Processor<WordOccurrence>(){
    public boolean process(    final WordOccurrence t){
      if (charsArray != null && t.getBaseText() == chars) {
        addOccurrence(consumer,charsArray,t.getStart(),t.getEnd(),convertToMask(t.getKind()));
      }
 else {
        addOccurrence(consumer,t.getBaseText(),t.getStart(),t.getEnd(),convertToMask(t.getKind()));
      }
      return true;
    }
    private int convertToMask(    final WordOccurrence.Kind kind){
      if (kind == null)       return UsageSearchContext.ANY;
      if (kind == WordOccurrence.Kind.CODE)       return UsageSearchContext.IN_CODE;
      if (kind == WordOccurrence.Kind.COMMENTS)       return UsageSearchContext.IN_COMMENTS;
      if (kind == WordOccurrence.Kind.LITERALS)       return UsageSearchContext.IN_STRINGS;
      if (kind == WordOccurrence.Kind.FOREIGN_LANGUAGE)       return UsageSearchContext.IN_FOREIGN_LANGUAGES;
      return 0;
    }
  }
);
  if (myHighlighter != null && myCommentTokens != null && IdCacheUtil.getIndexPatternCount() > 0) {
    final EditorHighlighter highlighter=HighlighterFactory.createHighlighter(null,myFile);
    highlighter.setText(chars);
    BaseFilterLexer.OccurrenceConsumer occurrenceConsumer=new IndexDataOccurrenceConsumer(new IndexDataConsumer<IdIndexEntry,Void>(){
      public void consume(      final IdIndexEntry key,      final Void value){
      }
    }
,true);
    final HighlighterIterator iterator=highlighter.createIterator(0);
    while (!iterator.atEnd()) {
      final IElementType token=iterator.getTokenType();
      if (IdCacheUtil.isInComments(token) || myCommentTokens.contains(token)) {
        BaseFilterLexer.advanceTodoItemsCount(chars.subSequence(iterator.getStart(),iterator.getEnd()),occurrenceConsumer);
      }
      iterator.advance();
    }
  }
}
