{
synchronized (myEnumerator) {
    LOG.info("Compacting " + myEnumerator.myFile.getPath());
    LOG.info("Live keys:" + ((int)(myLiveAndGarbageKeysCounter / LIVE_KEY_MASK)) + ", dead keys:"+ ((int)(myLiveAndGarbageKeysCounter & DEAD_KEY_NUMBER_MASK))+ ", read compaction size:"+ myReadCompactionGarbageSize);
    final long now=System.currentTimeMillis();
    final String newPath=getDataFile(myEnumerator.myFile).getPath() + ".new";
    final PersistentHashMapValueStorage newStorage=PersistentHashMapValueStorage.create(newPath);
    myValueStorage.switchToCompactionMode();
    long sizeBefore=myValueStorage.getSize();
    myLiveAndGarbageKeysCounter=0;
    myReadCompactionGarbageSize=0;
    try {
      if (doNewCompact()) {
        newCompact(newStorage);
      }
 else {
        traverseAllRecords(new PersistentEnumerator.RecordsProcessor(){
          @Override public boolean process(          final int keyId) throws IOException {
            final long record=readValueId(keyId);
            if (record != NULL_ADDR) {
              PersistentHashMapValueStorage.ReadResult readResult=myValueStorage.readBytes(record);
              long value=newStorage.appendBytes(readResult.buffer,0,readResult.buffer.length,0);
              updateValueId(keyId,value,record,null,getCurrentKey());
              myLiveAndGarbageKeysCounter+=LIVE_KEY_MASK;
            }
            return true;
          }
        }
);
      }
    }
  finally {
      newStorage.dispose();
    }
    myValueStorage.dispose();
    final long newSize=newStorage.getSize();
    FileUtil.rename(new File(newPath),getDataFile(myEnumerator.myFile));
    myValueStorage=PersistentHashMapValueStorage.create(getDataFile(myEnumerator.myFile).getPath());
    LOG.info("Compacted " + myEnumerator.myFile.getPath() + ":"+ sizeBefore+ " bytes into "+ newSize+ " bytes in "+ (System.currentTimeMillis() - now)+ "ms.");
    myEnumerator.putMetaData(myLiveAndGarbageKeysCounter);
    myEnumerator.putMetaData2(myLargeIndexWatermarkId);
  }
}
