{
  FileType ftype=file.getFileType();
  Language lang=null;
  if (ftype instanceof LanguageFileType) {
    lang=((LanguageFileType)ftype).getLanguage();
  }
  CommentsLiteralsSearchData data=model.getUserData(ourCommentsLiteralsSearchDataKey);
  if (data == null || !Comparing.equal(data.lastFile,file)) {
    SyntaxHighlighter highlighter=getHighlighter(file,lang);
    if (highlighter == null) {
      LOG.error("Syntax highlighter is null:" + file);
      return NOT_FOUND_RESULT;
    }
    TokenSet tokensOfInterest=TokenSet.EMPTY;
    Set<Language> relevantLanguages=null;
    if (lang != null) {
      final Language finalLang=lang;
      relevantLanguages=ApplicationManager.getApplication().runReadAction(new Computable<Set<Language>>(){
        @Override public Set<Language> compute(){
          THashSet<Language> result=new THashSet<Language>();
          for (          Project project : ProjectManager.getInstance().getOpenProjects()) {
            FileViewProvider viewProvider=PsiManager.getInstance(project).findViewProvider(file);
            if (viewProvider != null) {
              result.addAll(viewProvider.getLanguages());
              break;
            }
          }
          if (result.isEmpty()) {
            result.add(finalLang);
          }
          return result;
        }
      }
);
      for (      Language relevantLanguage : relevantLanguages) {
        tokensOfInterest=addTokenTypesForLanguage(model,relevantLanguage,tokensOfInterest);
      }
      if (model.isInStringLiteralsOnly()) {
        final Lexer xmlLexer=getHighlighter(null,Language.findLanguageByID("XML")).getHighlightingLexer();
        final String marker="xxx";
        xmlLexer.start("<a href=\"" + marker + "\" />");
        while (!marker.equals(xmlLexer.getTokenText())) {
          xmlLexer.advance();
          if (xmlLexer.getTokenType() == null)           break;
        }
        IElementType convenienceXmlAttrType=xmlLexer.getTokenType();
        if (convenienceXmlAttrType != null) {
          tokensOfInterest=TokenSet.orSet(tokensOfInterest,TokenSet.create(convenienceXmlAttrType));
        }
      }
    }
 else {
      relevantLanguages=ContainerUtil.newHashSet();
      if (ftype instanceof AbstractFileType) {
        if (model.isInCommentsOnly()) {
          tokensOfInterest=TokenSet.create(CustomHighlighterTokenType.LINE_COMMENT,CustomHighlighterTokenType.MULTI_LINE_COMMENT);
        }
        if (model.isInStringLiteralsOnly()) {
          tokensOfInterest=TokenSet.orSet(tokensOfInterest,TokenSet.create(CustomHighlighterTokenType.STRING,CustomHighlighterTokenType.SINGLE_QUOTED_STRING));
        }
      }
    }
    Matcher matcher=model.isRegularExpressions() ? compileRegExp(model,"") : null;
    StringSearcher searcher=matcher != null ? null : createStringSearcher(model);
    data=new CommentsLiteralsSearchData(file,relevantLanguages,highlighter,tokensOfInterest,searcher,matcher);
    model.putUserData(ourCommentsLiteralsSearchDataKey,data);
  }
  final Lexer lexer=data.highlightingLexer;
  lexer.start(text,model.isForward() && data.startOffset < offset ? data.startOffset : 0,text.length(),0);
  IElementType tokenType;
  TokenSet tokens=data.tokensOfInterest;
  int lastGoodOffset=0;
  boolean scanningForward=model.isForward();
  FindResultImpl prevFindResult=NOT_FOUND_RESULT;
  while ((tokenType=lexer.getTokenType()) != null) {
    if (lexer.getState() == 0)     lastGoodOffset=lexer.getTokenStart();
    final TextAttributesKey[] keys=data.highlighter.getTokenHighlights(tokenType);
    if (tokens.contains(tokenType) || (model.isInStringLiteralsOnly() && isHighlightedAsString(keys)) || (model.isInCommentsOnly() && isHighlightedAsDocComment(keys))) {
      int start=lexer.getTokenStart();
      int end=lexer.getTokenEnd();
      if (model.isInStringLiteralsOnly()) {
        char c=text.charAt(start);
        if (c == '"' || c == '\'') {
          while (start < end && c == text.charAt(start)) {
            ++start;
            if (c == text.charAt(end - 1) && start < end)             --end;
          }
        }
      }
      while (true) {
        FindResultImpl findResult=null;
        if (data.searcher != null) {
          int i=data.searcher.scan(text,textArray,start,end);
          if (i != -1 && i >= start) {
            final int matchEnd=i + model.getStringToFind().length();
            if (start >= offset || !scanningForward)             findResult=new FindResultImpl(i,matchEnd);
 else {
              start=matchEnd;
              continue;
            }
          }
        }
 else {
          data.matcher.reset(text.subSequence(start,end));
          if (data.matcher.find()) {
            final int matchEnd=start + data.matcher.end();
            if (start >= offset || !scanningForward) {
              findResult=new FindResultImpl(start + data.matcher.start(),matchEnd);
            }
 else {
              start=matchEnd;
              continue;
            }
          }
        }
        if (findResult != null) {
          if (scanningForward) {
            data.startOffset=lastGoodOffset;
            return findResult;
          }
 else {
            if (findResult.getEndOffset() >= offset)             return prevFindResult;
            prevFindResult=findResult;
            start=findResult.getEndOffset();
            continue;
          }
        }
        break;
      }
    }
 else {
      Language tokenLang=tokenType.getLanguage();
      if (tokenLang != lang && tokenLang != Language.ANY && !data.relevantLanguages.contains(tokenLang)) {
        tokens=addTokenTypesForLanguage(model,tokenLang,tokens);
        data.tokensOfInterest=tokens;
        data.relevantLanguages.add(tokenLang);
      }
    }
    lexer.advance();
  }
  return prevFindResult;
}
